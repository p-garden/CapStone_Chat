from langchain_openai import ChatOpenAI
from langchain_core.messages import AIMessage
import os
import re


class CounselorAgent:
    def __init__(self, client_info, persona_type, model_name="gpt-4o-mini", temperature=0.7):
        self.client_info = client_info
        self.llm = ChatOpenAI(model=model_name, temperature=temperature)

        # í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        persona_path = f"prompts/{persona_type}.txt"
        with open(persona_path, "r", encoding="utf-8") as f:
            self.persona_prompt = f.read()

        # ë©”ì¸ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        self.prompt_template = self.load_prompt_template()

    def load_prompt_template(self):
        with open("prompts/counselor_prompt.txt", "r", encoding="utf-8") as f:
            return f.read()

    def generate_response(self, history, current_input):
        formatted_history = "\n".join([
            f"{msg['role'].capitalize()}: {msg['message']}" for msg in history
        ])

        # ì¸ì‚¬ ë°˜ë³µ ë°©ì§€ ì•ˆë‚´
        extra_instruction = ""
        if len(history) > 0:
            extra_instruction = "\nâ€» ì´ì „ ì¸ì‚¬ ë‚´ìš©ì€ ì´ë¯¸ ì–¸ê¸‰ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë²ˆ ì‘ë‹µì—ì„œëŠ” ì¸ì‚¬ë§ì„ ë°˜ë³µí•˜ì§€ ë§ê³  ë³¸ë¡ ì— ì§‘ì¤‘í•´ ì£¼ì„¸ìš”."

        # ìµœì¢… í”„ë¡¬í”„íŠ¸ ì‘ì„±
        filled_prompt = self.prompt_template.format(
            persona_prompt=self.persona_prompt,
            client_info=self.client_info,
            history=formatted_history,
            current_input=current_input
        ) + extra_instruction

        # LLM í˜¸ì¶œ
        response = self.llm.invoke(filled_prompt)
        content = response.content if isinstance(response, AIMessage) else str(response)

        return self._parse_response(content)

    def _parse_response(self, text: str) -> dict:
        result = {
            "emotion": "ê°ì§€ë˜ì§€ ì•ŠìŒ",
            "distortion": "ê°ì§€ë˜ì§€ ì•ŠìŒ",
            "cbt_strategy": "ì „ëµ ì—†ìŒ",
            "reply": ""
        }

        # 1. ìƒë‹´ì‚¬ ì‘ë‹µ ì¶”ì¶œ (ì´ì „ë³´ë‹¤ ë” ìœ ì—°í•˜ê²Œ)
        reply_match = re.search(r"ìƒë‹´ì‚¬\s*ì‘ë‹µ[:ï¼š]?\s*(.*?)(?=\n\s*\[ê°ì •\]|\n\[ê°ì •\]|\Z)", text, re.DOTALL)
        if reply_match:
            result["reply"] = reply_match.group(1).strip()

        # 2. ê°ì •/ì¸ì§€/ì „ëµ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        meta_matches = re.findall(r"\[ê°ì •\](.*?)\|\s*\[ì¸ì§€ ì™œê³¡\](.*?)\|\s*\[ì „ëµ\](.*)", text)
        if meta_matches:
            # ê°€ì¥ ë§ˆì§€ë§‰ì— ë“±ì¥í•œ ë©”íƒ€ ì •ë³´ ì‚¬ìš©
            last_meta = meta_matches[-1]
            result["emotion"] = last_meta[0].strip()
            result["distortion"] = last_meta[1].strip()
            result["cbt_strategy"] = last_meta[2].strip()

        # 3. fallback: ìƒë‹´ì‚¬ ì‘ë‹µì´ ë¹„ì—ˆì„ ê²½ìš° í…ìŠ¤íŠ¸ ì „ì²´ ì‚¬ìš©
        if not result["reply"]:
            fallback = text.strip().split("\n")[0]
            if len(fallback) > 10:
                result["reply"] = fallback
            else:
                result["reply"] = "[âš ï¸ ìƒë‹´ì‚¬ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.]"

        print("[ğŸ” LLM ì‘ë‹µ ê²°ê³¼ ì „ì²´]:\n", text)
        return result
